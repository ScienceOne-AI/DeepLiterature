# encoding: utf-8
import os
import re
import time
import pandas as pd
import json
from datetime import datetime
import pytz

from config import LANGUAGE

def get_real_time_str():
    now_utc = datetime.now(pytz.utc)
    beijing_tz = pytz.timezone('Asia/Shanghai')
    now_beijing = now_utc.astimezone(beijing_tz)

    formatted_date = now_beijing.strftime("%Y-%m-%d")
    formatted_time = now_beijing.strftime("%H:%M:%S")
    return f"{formatted_date} {formatted_time}"

def get_location_by_ip():
    if LANGUAGE == "en":
        location_response = {
            "city": "Beijing",
            "regionName": "Beijing",
            "country": "China",
        }
    else:
        location_response = {
                "city": "åŒ—äº¬",
                "regionName": "åŒ—äº¬å¸‚",
                "country": "ä¸­å›½",
            }
    location_response = json.dumps(location_response)
    location_data = json.loads(location_response)
    
    
    city = location_data.get('city', 'æœªçŸ¥')
    region = location_data.get('regionName', 'æœªçŸ¥')
    country = location_data.get('country', 'æœªçŸ¥')

    return f"{city}, {region}, {country}"



def escape_ansi(line: str) -> str:
    # åˆ é™¤æ–‡æœ¬ä¸­çš„ ANSI è½¬ç§»åºåˆ—(ANSI è½¬ä¹‰åºåˆ—é€šå¸¸ç”¨äºæ§åˆ¶ç»ˆç«¯æ–‡æœ¬çš„æ ·å¼ï¼Œå¦‚é¢œè‰²ã€ç²—ä½“ã€ä¸‹åˆ’çº¿ç­‰)
    ansi_escape = re.compile(r'(?:\x1B[@-_]|[\x80-\x9F])[0-?]*[ -/]*[@-~]')
    return ansi_escape.sub('', line)

def split_process_jsonl(search_process):
    process_list = []
    for search_stage in search_process:
        is_websearch = False
        is_coderunner = False
        is_mclick = False
        content = ""
        for fc_option in search_stage:
            if fc_option['name'] == "webSearch":
                is_websearch = True
                content += ":grey-background[" + fc_option['keyword'] +"] "
            elif fc_option['name'] == "mclick":
                is_mclick = True
                fc_option['keyword'] = [idx + 1 for idx in fc_option['keyword']]
                for keyword in fc_option['keyword']:
                    content += ":blue-background[" + "ğŸ“ƒ" + str(keyword) +"] "
            elif fc_option['name'] == "CodeRunner":
                is_coderunner = True
                if len(fc_option['keyword']) > 19:
                    plat_text = fc_option['keyword'][:19].replace("\n", " ").replace("\r", " ")
                else:
                    plat_text = fc_option['keyword'].replace("\n", " ").replace("\r", " ")
                content += ":grey-background[" + f"ğŸ {plat_text}..." +"] "

        if is_websearch:   
            process_list.append("ğŸ¤– æ™ºèƒ½ä½“ Â· ç”Ÿæˆå…³é”®è¯ï¼š" + content)
            process_list.append("ğŸ” è°ƒå·¥å…· Â· æœç´¢å¼•æ“")

        if is_mclick:
            process_list.append("ğŸ¤– æ™ºèƒ½ä½“ Â· é€‰æ‹©ç½‘é¡µæ·±å…¥é˜…è¯»ï¼š" + content)
            process_list.append("ğŸ“– è°ƒå·¥å…· Â· ç½‘é¡µé˜…è¯»")
            # st.write("ğŸ“– æ‰“å¼€ï¼š" + content)

        if is_coderunner:
            process_list.append("ğŸ¤– æ™ºèƒ½ä½“ Â· ç”Ÿæˆä»£ç ï¼š" + content)
            process_list.append("ğŸ§© è°ƒå·¥å…· Â· ä»£ç æ‰§è¡Œ")

    return process_list

def find_special_text_and_numbers(text):
    pattern = r'â—¥\[(\d+(?:[,\ï¼Œ]\s*\d+)*)\]â—¤'
    matches = re.findall(pattern, text)

    # æå–æ–‡æœ¬å’Œæ•°å­—åˆ—è¡¨
    special_texts = [f'â—¥[{nums}]â—¤' for nums in matches]
    number_lists = [[int(num) for num in re.split(r'[,\ï¼Œ]', nums)] for nums in matches]
    return special_texts, number_lists

def replace_ref_tag2md(origin_llm_answer, url_list):
    new_llm_answer = origin_llm_answer
    special_texts, special_numbers = find_special_text_and_numbers(origin_llm_answer)
    for special_id, numbers in enumerate(special_numbers):
        replace_str = ""
        # éå†æ‰€æœ‰å¼•ç”¨çš„æ ‡è®°
        for number in numbers:
            if number < len(url_list):
                new_title = url_list[number]['title'].replace('"', "'")
                replace_str += f" [:blue-background[{number + 1}]]({url_list[number]['url']} \"{new_title}\") "
            else:
                replace_str = ""
        new_llm_answer = new_llm_answer.replace(special_texts[special_id], replace_str)

    return new_llm_answer

def text_finish(idx, text):
    numbers = ['1ï¸âƒ£', '2ï¸âƒ£', '3ï¸âƒ£', '4ï¸âƒ£', '5ï¸âƒ£', '6ï¸âƒ£', '7ï¸âƒ£', '8ï¸âƒ£', '9ï¸âƒ£', 'ğŸ”Ÿ']
    return "*:grey[" + numbers[idx-1] + " ~~" + text  + "~~]*  [:green[å·²å®Œæˆ]]"

def text_render(idx, text):
    numbers = ['1ï¸âƒ£', '2ï¸âƒ£', '3ï¸âƒ£', '4ï¸âƒ£', '5ï¸âƒ£', '6ï¸âƒ£', '7ï¸âƒ£', '8ï¸âƒ£', '9ï¸âƒ£', 'ğŸ”Ÿ']
    if "å·²å®Œæˆ" in text:
        return text
    return numbers[idx-1] + " " + text

def is_mobile(user_agent):
    mobile_keywords = [
        'Android', 'iPhone', 'iPad', 'Windows Phone', 'Mobile', 'Symbian',
        'BlackBerry', 'Opera Mini', 'IEMobile', 'UCBrowser', 'MQQBrowser'
    ]
    
    # æ£€æŸ¥User-Agentä¸­æ˜¯å¦åŒ…å«æ‰‹æœºç«¯çš„å…³é”®è¯
    for keyword in mobile_keywords:
        if keyword.lower() in user_agent.lower():
            return True
    return False


def latex_render(text):
    text = text.replace("\\(","$").replace("\\)","$")  
    lines = text.splitlines()
    final_text = []
    for line in lines:
        if line[:6] == "![fig-":
            continue
        final_text.append(line)
    return "\n".join(final_text)

def yield_text(text, speed = 0.02):
    # æ¨¡æ‹Ÿæµå¼è¾“å‡º
    i = 0  # ç”¨æ¥è·Ÿè¸ªå½“å‰å¤„ç†çš„å­—ç¬¦ä½ç½®
    while i < len(text):
        if text[i:i+17] == ":blue-background[" or text[i:i+17] == ":grey-background[":
            end_pos = i + 17  # è·³è¿‡ ":blue-background["
            while end_pos < len(text) and text[end_pos] not in [']']:
                end_pos += 1
            if end_pos < len(text):  # æ‰¾åˆ°åŒ¹é…çš„ç»“æŸç¬¦
                end_pos += 1  # åŒ…å«é—­åˆç¬¦å·
                yield text[i:end_pos]  # ä¸€æ¬¡æ€§è¿”å›è¿™ä¸€éƒ¨åˆ†
                i = end_pos  # æ›´æ–° i è·³åˆ°ä¸‹ä¸€ä¸ªä½ç½®
        # æ£€æŸ¥æ˜¯å¦é‡åˆ°ä»¥ http å¼€å¤´çš„å­—ç¬¦ä¸²
        elif text[i:i+4] == "http":
            end_pos = i + 4  # è·³è¿‡ "http"
            while end_pos < len(text) and text[end_pos] not in [")", "\n"]:
                end_pos += 1
            yield text[i:end_pos]  # ä¸€æ¬¡æ€§è¿”å›è¿™ä¸€æ®µ URLï¼Œå¤„ç†æ ‡é¢˜ä¸­ä¹±ç çš„é—®é¢˜
            i = end_pos  # æ›´æ–° i è·³åˆ°ä¸‹ä¸€ä¸ªä½ç½®
        else:
            # å¦‚æœæ²¡æœ‰ç‰¹æ®Šæ ¼å¼ï¼Œé€å­—ç¬¦è¿”å›
            yield text[i]
            i += 1
        time.sleep(speed)  # æ¨¡æ‹Ÿæµå¼è¿”å›çš„å»¶è¿Ÿ

def merge_jsonl(folder_path = "./datasets/web_8_turns"):
    # åˆå§‹åŒ–ä¸€ä¸ªç©ºçš„ DataFrame
    all_data = pd.DataFrame()

    # éå†æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰çš„ .jsonl æ–‡ä»¶
    for filename in os.listdir(folder_path):
        if filename.endswith('.jsonl'):
            file_path = os.path.join(folder_path, filename)
            df = pd.read_json(file_path, lines=True)
            df = df[df['messages'].apply(lambda x: len(x) >= 8)]
            all_data = pd.concat([all_data, df], ignore_index=True)

    return all_data
